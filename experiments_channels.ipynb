{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MycsshgndcYI"
      },
      "outputs": [],
      "source": [
        "from utils.fetch_dataset import fetch_dataset\n",
        "from utils.quality_measures import *\n",
        "from utils.save_plots import output_scatter_plot\n",
        "from utils.adjust_tensor import adjust_tensor\n",
        "\n",
        "from dataset import MRIDataset\n",
        "from unet import UNet3D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "T7dpHzNWlp27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53fdf774-380e-4e9a-cd0a-03a86f853485"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1aIzlyrPTgrzLKwGS1_3alvNJKgLvbGQ3\n",
            "From (redirected): https://drive.google.com/uc?id=1aIzlyrPTgrzLKwGS1_3alvNJKgLvbGQ3&confirm=t&uuid=fc10ab53-6a30-4ac2-96ef-6a96bf8b8930\n",
            "To: /content/classes.zip\n",
            "100%|██████████| 6.94M/6.94M [00:00<00:00, 96.4MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1ki-aYI07KEbi7mWsPWxeAvmMfVsWrBCq\n",
            "From (redirected): https://drive.google.com/uc?id=1ki-aYI07KEbi7mWsPWxeAvmMfVsWrBCq&confirm=t&uuid=c764e275-c299-4d98-ab01-6813980b5cef\n",
            "To: /content/patients.zip\n",
            "100%|██████████| 2.27G/2.27G [00:18<00:00, 124MB/s]\n"
          ]
        }
      ],
      "source": [
        "fetch_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RN4BdO3TVg2i"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 1\n",
        "IN_CHANNELS = 1\n",
        "EPOCHS = 1\n",
        "\n",
        "SHOW_IMAGES = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOP3cX3aXW45",
        "outputId": "647a9ee3-7fcc-4252-bfb8-b1889bdb8062"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "l5yCZcBrRZwy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def adjust_tensor(data, mask):\n",
        "    _, _, D, H, W = data.shape\n",
        "\n",
        "    assert H % 2 == 0 and W % 2 == 0, \"Wymiary H i W muszą być podzielne przez 2.\"\n",
        "\n",
        "    yield data[:, :, :D//2, :H//2, :W//2], mask[:, :, :D//2, :H//2, :W//2]\n",
        "\n",
        "    yield data[:, :, :D//2, :H//2, W//2:], mask[:, :, :D//2, :H//2, W//2:]\n",
        "\n",
        "    yield data[:, :, :D//2, H//2:, :W//2], mask[:, :, :D//2, H//2:, :W//2]\n",
        "\n",
        "    yield data[:, :, :D//2, H//2:, W//2:], mask[:, :, :D//2, H//2:, W//2:]\n",
        "\n",
        "    yield data[:, :, D//2:, :H//2, :W//2], mask[:, :, D//2:, :H//2, :W//2]\n",
        "\n",
        "    yield data[:, :, D//2:, :H//2, W//2:], mask[:, :, D//2:, :H//2, W//2:]\n",
        "\n",
        "    yield data[:, :, D//2:, H//2:, :W//2], mask[:, :, D//2:, H//2:, :W//2]\n",
        "\n",
        "    yield data[:, :, D//2:, H//2:, W//2:], mask[:, :, D//2:, H//2:, W//2:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "collapsed": true,
        "id": "L_V0XpDeyJVK"
      },
      "outputs": [],
      "source": [
        "from torch.nn import BCEWithLogitsLoss\n",
        "from torch.optim import Adam\n",
        "\n",
        "def train_model(train_dataloader, model):\n",
        "\n",
        "  criterion = BCEWithLogitsLoss()\n",
        "  optimizer = Adam(params=model.parameters())\n",
        "\n",
        "  model = model.to(device)\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "      train_loss = 0.0\n",
        "      model.train()\n",
        "      i = 0\n",
        "      for idx, (data, mask) in enumerate(train_dataloader):\n",
        "        for part_idx, (chunked_data, chunked_mask) in enumerate(adjust_tensor(data, mask.unsqueeze(0))):\n",
        "          chunked_data = chunked_data.float().to(device)\n",
        "          chunked_mask = chunked_mask.float().to(device)\n",
        "          optimizer.zero_grad()\n",
        "          output = model(chunked_data)\n",
        "          loss = criterion(output, chunked_mask)\n",
        "          if i % 3 == 0:\n",
        "            print(f\"Scan loss: {loss}\")\n",
        "            output_scatter_plot((output.squeeze(0).squeeze(0) > 0).float(), chunked_mask.squeeze(0).squeeze(0), epoch, idx, part_idx)\n",
        "          print(\"A\")\n",
        "          loss.backward()\n",
        "          print(\"B\")\n",
        "          optimizer.step()\n",
        "\n",
        "          train_loss += loss.item()\n",
        "          i += 1\n",
        "\n",
        "      print(f\"Loss: {train_loss / i}\")\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "_oJ0JGiZR5ld"
      },
      "outputs": [],
      "source": [
        "def eval_model(test_dataloader, model):\n",
        "  model.eval()\n",
        "  i = 0\n",
        "  for idx, (data, mask) in enumerate(test_dataloader):\n",
        "      data = data.float().to(device)\n",
        "      mask = mask.float().to(device)\n",
        "      for part_idx, (chunked_data, chunked_mask) in enumerate(adjust_tensor(data, mask.unsqueeze(0))):\n",
        "          chunked_data = chunked_data.float().to(device)\n",
        "          chunked_mask = chunked_mask.float().to(device).squeeze(0).squeeze(0)\n",
        "          output = model(chunked_data).squeeze(0).squeeze(0)\n",
        "\n",
        "          evaluate(output, chunked_mask)\n",
        "\n",
        "          if SHOW_IMAGES:\n",
        "            output_scatter_plot((output > 0).float(), chunked_mask, None, idx, part_idx)\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "channel_labels = ['ch1', 'ch2', 'ch3']\n",
        "\n",
        "for channel_label in channel_labels:\n",
        "  print(f\"Channel: {channel_label}\")\n",
        "  dataset = MRIDataset(patients_dir = f\"./patients/{channel_label}\")\n",
        "  train_dataset, test_dataset = torch.utils.data.random_split(dataset, [0.8, 0.2])\n",
        "  train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "  test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "  model = UNet3D(IN_CHANNELS, 1)\n",
        "  model = train_model(train_dataloader, model)\n",
        "  model = eval_model(test_dataloader, model)"
      ],
      "metadata": {
        "id": "keP06kiZad1D"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}